//! Native game streaming via FFmpeg WHIP
//!
//! This module provides:
//! - Screen/window enumeration via Windows API
//! - FFmpeg sidecar management for WHIP streaming
//! - Stream status monitoring

use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use std::fs::OpenOptions;
use std::io::Write;
use tauri::api::process::{Command, CommandChild, CommandEvent};
use tauri::{AppHandle, Manager};

/// Capture source (screen or window)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CaptureSource {
    pub id: String,
    pub name: String,
    pub source_type: String, // "screen" or "window"
    pub width: Option<u32>,
    pub height: Option<u32>,
}

/// Stream configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StreamConfig {
    pub source_id: String,
    pub whip_url: String,
    pub width: u32,
    pub height: u32,
    pub fps: u32,
    pub bitrate: u32,        // in kbps
    pub encoder: String,     // "nvenc", "qsv", "amf", "x264"
    pub preset: String,      // encoder preset (p1-p7 for nvenc)
    pub audio_enabled: bool,
    pub bearer_token: Option<String>,
}

/// Stream status
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StreamStatus {
    pub active: bool,
    pub source_id: Option<String>,
    pub whip_url: Option<String>,
    pub duration_seconds: u64,
    pub error: Option<String>,
}

/// FFmpeg availability info
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FFmpegInfo {
    pub available: bool,
    pub version: Option<String>,
    pub encoders: Vec<String>,
    pub whip_support: bool,
}

/// Shared state that can be sent across threads
#[derive(Clone, Default)]
pub struct SharedState {
    pub last_error: Arc<Mutex<Option<String>>>,
    pub is_running: Arc<Mutex<bool>>,
}

/// State for managing streams
pub struct StreamingState {
    ffmpeg_child: Mutex<Option<CommandChild>>,
    current_config: Mutex<Option<StreamConfig>>,
    start_time: Mutex<Option<std::time::Instant>>,
    shared: SharedState,
}

impl Default for StreamingState {
    fn default() -> Self {
        Self {
            ffmpeg_child: Mutex::new(None),
            current_config: Mutex::new(None),
            start_time: Mutex::new(None),
            shared: SharedState::default(),
        }
    }
}

/// Log to debug file (Windows)
fn log_to_file(message: &str) {
    #[cfg(target_os = "windows")]
    {
        if let Ok(mut file) = OpenOptions::new()
            .create(true)
            .append(true)
            .open("C:\\Users\\VOLTA\\ffmpeg_debug.log")
        {
            let timestamp = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .map(|d| d.as_secs())
                .unwrap_or(0);
            let _ = writeln!(file, "[{}] {}", timestamp, message);
        }
    }
    #[cfg(not(target_os = "windows"))]
    {
        log::info!("{}", message);
    }
}

/// List available capture sources (screens and windows)
#[tauri::command]
pub async fn list_capture_sources() -> Result<Vec<CaptureSource>, String> {
    #[cfg(target_os = "windows")]
    {
        use std::panic;
        
        // Try to enumerate sources, fall back to desktop-only on error
        let result = panic::catch_unwind(|| {
            list_windows_sources_safe()
        });
        
        match result {
            Ok(Ok(sources)) if !sources.is_empty() => Ok(sources),
            _ => {
                // Fallback to just desktop
                Ok(vec![CaptureSource {
                    id: "desktop".to_string(),
                    name: "Desktop (Full Screen)".to_string(),
                    source_type: "screen".to_string(),
                    width: None,
                    height: None,
                }])
            }
        }
    }
    #[cfg(not(target_os = "windows"))]
    {
        Ok(vec![CaptureSource {
            id: "desktop".to_string(),
            name: "Desktop".to_string(),
            source_type: "screen".to_string(),
            width: None,
            height: None,
        }])
    }
}

#[cfg(target_os = "windows")]
fn list_windows_sources_safe() -> Result<Vec<CaptureSource>, String> {
    use windows::Win32::Foundation::{BOOL, HWND, LPARAM, RECT};
    use windows::Win32::UI::WindowsAndMessaging::{
        EnumWindows, GetWindowRect, GetWindowTextLengthW, GetWindowTextW, IsWindowVisible,
        GetWindowLongW, GWL_EXSTYLE, WS_EX_TOOLWINDOW,
    };
    
    let mut sources = Vec::new();
    
    // Always add desktop first
    sources.push(CaptureSource {
        id: "desktop".to_string(),
        name: "Desktop (Full Screen)".to_string(),
        source_type: "screen".to_string(),
        width: None,
        height: None,
    });
    
    // Enumerate windows
    unsafe {
        unsafe extern "system" fn enum_callback(hwnd: HWND, lparam: LPARAM) -> BOOL {
            let sources = &mut *(lparam.0 as *mut Vec<CaptureSource>);
            
            // Skip invisible windows
            if !IsWindowVisible(hwnd).as_bool() {
                return BOOL(1);
            }
            
            // Skip tool windows
            let ex_style = GetWindowLongW(hwnd, GWL_EXSTYLE) as u32;
            if ex_style & WS_EX_TOOLWINDOW.0 != 0 {
                return BOOL(1);
            }
            
            // Get window title
            let title_len = GetWindowTextLengthW(hwnd);
            if title_len == 0 {
                return BOOL(1);
            }
            
            let mut title_buf = vec![0u16; (title_len + 1) as usize];
            let len = GetWindowTextW(hwnd, &mut title_buf);
            if len == 0 {
                return BOOL(1);
            }
            
            let title = String::from_utf16_lossy(&title_buf[..len as usize]);
            
            // Filter out system windows
            let skip_titles = [
                "Program Manager",
                "Windows Input Experience",
                "Microsoft Text Input",
                "NVIDIA GeForce Overlay",
                "AMD Software",
                "Settings",
                "Task View",
                "Search",
                "",
            ];
            
            if skip_titles.iter().any(|&s| title.starts_with(s) || title == s) {
                return BOOL(1);
            }
            
            // Get window size
            let mut rect = RECT::default();
            if GetWindowRect(hwnd, &mut rect).is_ok() {
                let width = (rect.right - rect.left) as u32;
                let height = (rect.bottom - rect.top) as u32;
                
                // Skip tiny windows
                if width < 200 || height < 150 {
                    return BOOL(1);
                }
                
                // Limit to 20 windows max
                if sources.len() >= 21 {
                    return BOOL(0); // Stop enumeration
                }
                
                // Use title= format for gdigrab
                let escaped_title = title.replace("\"", "\\\"");
                sources.push(CaptureSource {
                    id: format!("title={}", escaped_title),
                    name: if title.len() > 45 {
                        format!("{}...", &title[..42])
                    } else {
                        title
                    },
                    source_type: "window".to_string(),
                    width: Some(width),
                    height: Some(height),
                });
            }
            
            BOOL(1)
        }
        
        let sources_ptr = &mut sources as *mut Vec<CaptureSource>;
        let _ = EnumWindows(Some(enum_callback), LPARAM(sources_ptr as isize));
    }
    
    Ok(sources)
}

/// Start streaming to WHIP endpoint
#[tauri::command]
pub async fn start_stream(
    app: AppHandle,
    config: StreamConfig,
) -> Result<(), String> {
    let state = app.state::<StreamingState>();

    {
        let child = state.ffmpeg_child.lock().map_err(|e| e.to_string())?;
        if child.is_some() {
            return Err("Already streaming".to_string());
        }
    }

    let ffmpeg_args = build_ffmpeg_args(&config)?;
    
    // Log the full FFmpeg command for debugging
    let cmd_str = format!("ffmpeg {}", ffmpeg_args.join(" "));
    log::info!("[FFmpeg] Starting: {}", cmd_str);
    log_to_file(&format!("Starting FFmpeg: {}", cmd_str));

    let (mut rx, child) = Command::new_sidecar("ffmpeg")
        .map_err(|e| format!("Failed to create FFmpeg sidecar: {}", e))?
        .args(&ffmpeg_args)
        .spawn()
        .map_err(|e| format!("Failed to spawn FFmpeg: {}", e))?;

    {
        let mut child_lock = state.ffmpeg_child.lock().map_err(|e| e.to_string())?;
        *child_lock = Some(child);
    }
    {
        let mut config_lock = state.current_config.lock().map_err(|e| e.to_string())?;
        *config_lock = Some(config);
    }
    {
        let mut start_lock = state.start_time.lock().map_err(|e| e.to_string())?;
        *start_lock = Some(std::time::Instant::now());
    }
    {
        let mut error_lock = state.shared.last_error.lock().map_err(|e| e.to_string())?;
        *error_lock = None;
    }
    {
        let mut running = state.shared.is_running.lock().map_err(|e| e.to_string())?;
        *running = true;
    }

    let shared = state.shared.clone();

    tauri::async_runtime::spawn(async move {
        while let Some(event) = rx.recv().await {
            match event {
                CommandEvent::Stderr(line) => {
                    log::info!("[FFmpeg] {}", line);
                    log_to_file(&line);
                    if line.contains("Error") || line.contains("error") {
                        if let Ok(mut error) = shared.last_error.lock() {
                            *error = Some(line);
                        }
                    }
                }
                CommandEvent::Stdout(line) => {
                    log::debug!("[FFmpeg stdout] {}", line);
                    log_to_file(&format!("[stdout] {}", line));
                }
                CommandEvent::Terminated(payload) => {
                    let msg = format!("FFmpeg exited with code: {:?}, signal: {:?}", 
                        payload.code, payload.signal);
                    log::error!("[FFmpeg] {}", msg);
                    log_to_file(&msg);
                    if let Ok(mut running) = shared.is_running.lock() {
                        *running = false;
                    }
                    break;
                }
                _ => {}
            }
        }
    });

    Ok(())
}

/// Stop streaming
#[tauri::command]
pub async fn stop_stream(app: AppHandle) -> Result<(), String> {
    let state = app.state::<StreamingState>();

    let child_opt = {
        let mut child_lock = state.ffmpeg_child.lock().map_err(|e| e.to_string())?;
        child_lock.take()
    };

    if let Some(mut child) = child_opt {
        log_to_file("Stopping FFmpeg (kill)");
        // Immediately kill FFmpeg - no graceful quit
        let _ = child.kill();
    }

    {
        let mut config = state.current_config.lock().map_err(|e| e.to_string())?;
        *config = None;
    }
    {
        let mut start = state.start_time.lock().map_err(|e| e.to_string())?;
        *start = None;
    }
    {
        let mut running = state.shared.is_running.lock().map_err(|e| e.to_string())?;
        *running = false;
    }

    Ok(())
}

/// Get current stream status
#[tauri::command]
pub async fn get_stream_status(app: AppHandle) -> Result<StreamStatus, String> {
    let state = app.state::<StreamingState>();

    let child = state.ffmpeg_child.lock().map_err(|e| e.to_string())?;
    let config = state.current_config.lock().map_err(|e| e.to_string())?;
    let start_time = state.start_time.lock().map_err(|e| e.to_string())?;
    let last_error = state.shared.last_error.lock().map_err(|e| e.to_string())?;

    let active = child.is_some();
    let duration_seconds = start_time
        .as_ref()
        .map(|t| t.elapsed().as_secs())
        .unwrap_or(0);

    Ok(StreamStatus {
        active,
        source_id: config.as_ref().map(|c| c.source_id.clone()),
        whip_url: config.as_ref().map(|c| c.whip_url.clone()),
        duration_seconds,
        error: last_error.clone(),
    })
}

/// Check FFmpeg availability and capabilities
#[tauri::command]
pub async fn check_ffmpeg() -> Result<FFmpegInfo, String> {
    let version_result = Command::new_sidecar("ffmpeg")
        .map_err(|e| e.to_string())?
        .args(["-version"])
        .output();

    let version_output = match version_result {
        Ok(output) => output,
        Err(_) => {
            return Ok(FFmpegInfo {
                available: false,
                version: None,
                encoders: vec![],
                whip_support: false,
            });
        }
    };

    let version_str = &version_output.stdout;
    let version = version_str
        .lines()
        .next()
        .and_then(|l| l.split_whitespace().nth(2))
        .map(|s| s.to_string());

    let encoders_output = Command::new_sidecar("ffmpeg")
        .map_err(|e| e.to_string())?
        .args(["-encoders", "-hide_banner"])
        .output()
        .map_err(|e| e.to_string())?;

    let encoders_str = &encoders_output.stdout;
    let mut encoders = Vec::new();

    if encoders_str.contains("h264_nvenc") {
        encoders.push("nvenc".to_string());
    }
    if encoders_str.contains("h264_qsv") {
        encoders.push("qsv".to_string());
    }
    if encoders_str.contains("h264_amf") {
        encoders.push("amf".to_string());
    }
    if encoders_str.contains("libx264") {
        encoders.push("x264".to_string());
    }

    let formats_output = Command::new_sidecar("ffmpeg")
        .map_err(|e| e.to_string())?
        .args(["-muxers", "-hide_banner"])
        .output()
        .map_err(|e| e.to_string())?;

    let formats_str = &formats_output.stdout;
    let whip_support = formats_str.contains(" whip ");

    Ok(FFmpegInfo {
        available: true,
        version,
        encoders,
        whip_support,
    })
}

/// Build FFmpeg command arguments - optimized for WHIP streaming
fn build_ffmpeg_args(config: &StreamConfig) -> Result<Vec<String>, String> {
    let mut args = Vec::new();

    // Global options - optimized for low latency WHIP
    args.extend([
        "-hide_banner".to_string(),
        "-loglevel".to_string(), "info".to_string(),
        // Critical: nobuffer + flush_packets for real-time streaming
        "-fflags".to_string(), "+genpts+nobuffer+flush_packets".to_string(),
        "-flags".to_string(), "low_delay".to_string(),
        "-max_delay".to_string(), "0".to_string(),
        "-y".to_string(),
        "-nostdin".to_string(),
    ]);

    // Input source (Windows gdigrab)
    #[cfg(target_os = "windows")]
    {
        args.extend([
            // Reduced buffer for lower latency
            "-rtbufsize".to_string(), "64M".to_string(),
            "-thread_queue_size".to_string(), "512".to_string(),
            // Fast probing
            "-probesize".to_string(), "32".to_string(),
            "-analyzeduration".to_string(), "0".to_string(),
            // GDI grab
            "-f".to_string(), "gdigrab".to_string(),
            "-draw_mouse".to_string(), "1".to_string(),
            "-framerate".to_string(), config.fps.to_string(),
        ]);
        
        // Handle window capture vs desktop
        if config.source_id.starts_with("title=") {
            // Window capture: use title directly
            args.extend(["-i".to_string(), config.source_id.clone()]);
        } else {
            // Desktop capture
            args.extend(["-i".to_string(), "desktop".to_string()]);
        }
    }

    #[cfg(not(target_os = "windows"))]
    {
        args.extend([
            "-f".to_string(), "x11grab".to_string(),
            "-framerate".to_string(), config.fps.to_string(),
            "-i".to_string(), ":0.0".to_string(),
        ]);
    }

    // Audio input (optional)
    if config.audio_enabled {
        #[cfg(target_os = "windows")]
        {
            args.extend([
                "-f".to_string(), "dshow".to_string(),
                "-i".to_string(), "audio=virtual-audio-capturer".to_string(),
            ]);
        }
    }

    // Video filter - only resize if captured size differs from target
    // Using fast_bilinear for speed
    args.extend([
        "-vf".to_string(),
        format!("scale={}:{}:flags=fast_bilinear", config.width, config.height),
    ]);

    // Video encoder with ultra-low latency settings
    match config.encoder.as_str() {
        "nvenc" => {
            args.extend([
                "-c:v".to_string(), "h264_nvenc".to_string(),
                "-preset".to_string(), "p1".to_string(),
                "-tune".to_string(), "ull".to_string(),
                "-rc".to_string(), "cbr".to_string(),
                "-b:v".to_string(), format!("{}k", config.bitrate),
                "-maxrate".to_string(), format!("{}k", config.bitrate),
                "-bufsize".to_string(), format!("{}k", config.bitrate / 4),
                "-profile:v".to_string(), "baseline".to_string(),
                "-bf".to_string(), "0".to_string(),
                "-g".to_string(), (config.fps * 2).to_string(),
                "-keyint_min".to_string(), config.fps.to_string(),
                "-rc-lookahead".to_string(), "0".to_string(),
            ]);
        }
        "qsv" => {
            args.extend([
                "-c:v".to_string(), "h264_qsv".to_string(),
                "-preset".to_string(), "veryfast".to_string(),
                "-profile:v".to_string(), "baseline".to_string(),
                "-bf".to_string(), "0".to_string(),
                "-b:v".to_string(), format!("{}k", config.bitrate),
                "-g".to_string(), (config.fps * 2).to_string(),
            ]);
        }
        "amf" => {
            args.extend([
                "-c:v".to_string(), "h264_amf".to_string(),
                "-usage".to_string(), "ultralowlatency".to_string(),
                "-profile:v".to_string(), "baseline".to_string(),
                "-bf".to_string(), "0".to_string(),
                "-b:v".to_string(), format!("{}k", config.bitrate),
                "-g".to_string(), (config.fps * 2).to_string(),
            ]);
        }
        _ => {
            // x264 fallback - WHIP optimized settings
            args.extend([
                "-c:v".to_string(), "libx264".to_string(),
                "-preset".to_string(), "ultrafast".to_string(),  // Fastest preset
                "-tune".to_string(), "zerolatency".to_string(),  // Essential for WHIP
                "-profile:v".to_string(), "baseline".to_string(), // No B-frames
                "-bf".to_string(), "0".to_string(),              // Explicitly no B-frames
                "-b:v".to_string(), format!("{}k", config.bitrate),
                "-bufsize".to_string(), format!("{}k", config.bitrate / 4),
                "-g".to_string(), (config.fps * 2).to_string(),   // 2 second GOP
                "-threads".to_string(), "1".to_string(),          // Single thread for WHIP
            ]);
        }
    }

    // Pixel format for WebRTC compatibility
    args.extend(["-pix_fmt".to_string(), "yuv420p".to_string()]);

    // Audio encoder
    if config.audio_enabled {
        args.extend([
            "-c:a".to_string(), "libopus".to_string(),
            "-ar".to_string(), "48000".to_string(),
            "-ac".to_string(), "2".to_string(),
            "-b:a".to_string(), "128k".to_string(),
        ]);
    } else {
        args.push("-an".to_string());
    }

    // WHIP output with flush
    args.extend([
        "-flush_packets".to_string(), "1".to_string(),
        "-ts_buffer_size".to_string(), "2000000".to_string(),
        "-whip_flags".to_string(), "dtls_active".to_string(),
        "-f".to_string(), "whip".to_string(),
    ]);

    // Bearer token
    if let Some(ref token) = config.bearer_token {
        args.extend(["-authorization".to_string(), token.clone()]);
    }

    // WHIP endpoint
    args.push(config.whip_url.clone());

    Ok(args)
}
